{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "history_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edrihan/chessvid/blob/main/tortoise_tts_chess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font face=\"Trebuchet MS\" size=\"6\">Tortoise TTS<font color=\"#999\" size=\"4\">&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;</font><font color=\"#999\" size=\"4\">Text to spoken word audio</font><font color=\"#999\" size=\"4\">&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;</font><a href=\"https://github.com/olaviinha/NeuralTextToAudio\" target=\"_blank\"><font color=\"#999\" size=\"4\">Github</font></a>\n",
        "\n",
        "- All file and directory paths should be relative to your Google Drive root (_My Drive_). E.g. `voice_audio` value should be `Audio/test-voice.wav`, if you have a directory called _Audio_ in your drive, and you want to use _test-voice.wav_ from that directory. Paths are case-sensitive.\n",
        "- This notebook will attempt to prepare a coherent voice dataset from `voice_audio` input, but optimal `voice_audio` for coherent output should be a path to a WAV file of about 1 minute in duration, or a directory containing a total of about 1 minute of WAV files.\n",
        "- In case `voice_audio` contents exceeds 1 minute considerably, random clips (from random file, or files depending on contents, if directory given) will be picked for voice cloning."
      ],
      "metadata": {
        "id": "GBgr33OisX3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Setup\n",
        "#@markdown This cell needs to be run only once. It will mount your Google Drive and setup prerequisites.<br>\n",
        "#@markdown <small>Mounting Drive will enable this notebook to save outputs directly to your Drive. Otherwise you will need to copy/download them manually from this notebook.</small>\n",
        "\n",
        "force_setup = False\n",
        "repositories = ['https://github.com/neonbjb/tortoise-tts.git']\n",
        "pip_packages = 'scipy transformers==4.19.0'\n",
        "apt_packages = 'sox'\n",
        "mount_drive = False #@param {type:\"boolean\"}\n",
        "skip_setup = False #@ param {type:\"boolean\"}\n",
        "\n",
        "# Download the repo from Github\n",
        "import os\n",
        "from google.colab import output\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%cd /content/\n",
        "\n",
        "# inhagcutils\n",
        "if not os.path.isfile('/content/inhagcutils.ipynb') and force_setup == False:\n",
        "  !pip -q install import-ipynb {pip_packages}\n",
        "  if apt_packages != '':\n",
        "    !apt-get update && apt-get install {apt_packages}\n",
        "  !curl -s -O https://raw.githubusercontent.com/olaviinha/inhagcutils/master/inhagcutils.ipynb\n",
        "import import_ipynb\n",
        "from inhagcutils import *\n",
        "\n",
        "# Mount Drive\n",
        "if mount_drive == True:\n",
        "  if not os.path.isdir('/content/drive'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    drive_root = '/content/drive/My Drive'\n",
        "  if not os.path.isdir('/content/mydrive'):\n",
        "    os.symlink('/content/drive/My Drive', '/content/mydrive')\n",
        "    drive_root = '/content/mydrive/'\n",
        "  drive_root_set = True\n",
        "else:\n",
        "  create_dirs(['/content/faux_drive'])\n",
        "  drive_root = '/content/faux_drive/'\n",
        "\n",
        "if len(repositories) > 0 and skip_setup == False:\n",
        "  for repo in repositories:\n",
        "    %cd /content/\n",
        "    install_dir = fix_path('/content/'+path_leaf(repo).replace('.git', ''))\n",
        "    repo = repo if '.git' in repo else repo+'.git'\n",
        "    !git clone {repo}\n",
        "    if os.path.isfile(install_dir+'requirements.txt'):\n",
        "      !pip install -r {install_dir}/requirements.txt\n",
        "    if os.path.isfile(install_dir+'setup.py') or os.path.isfile(install_dir+'setup.cfg'):\n",
        "      !pip install -e {install_dir}\n",
        "\n",
        "if len(repositories) == 1:\n",
        "  %cd {install_dir}\n",
        "\n",
        "dir_tmp = '/content/tmp/'\n",
        "dir_tmp_corpus = '/content/tmp/corpus/'\n",
        "dir_tmp_slices = '/content/tmp/slices/'\n",
        "dir_tmp_clips = '/content/tmp/clips/'\n",
        "dir_tmp_processed = '/content/tmp/processed/'\n",
        "create_dirs([dir_tmp, dir_tmp_corpus, dir_tmp_slices, dir_tmp_clips, dir_tmp_processed])\n",
        "\n",
        "import time, sys\n",
        "from datetime import timedelta\n",
        "import math\n",
        "\n",
        "# Imports used through the rest of the notebook.\n",
        "import torch\n",
        "import torchaudio\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import IPython\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "from tortoise.api import TextToSpeech\n",
        "from tortoise.utils.audio import load_audio, load_voice, load_voices\n",
        "\n",
        "def slice_to_frames(audio_data, slice_duration, fade_in=0, fade_out=0, sr=44100):\n",
        "  a_duration = librosa.get_duration(audio_data, sr=sr)\n",
        "  clips = math.ceil(a_duration/slice_duration)\n",
        "  frames = []\n",
        "  for i in range(clips-1):\n",
        "    if i > 0 and i < clips:\n",
        "      start = i*slice_duration\n",
        "      audio_clip = clip_audio(audio_data, start, slice_duration)\n",
        "      if fade_in > 0 or fade_out > 0:\n",
        "        audio_clip = fade_audio(audio_clip, fade_in, fade_out, sr=sr)\n",
        "      frames.append(audio_clip)\n",
        "  return frames\n",
        "\n",
        "def clip_audio(audio_data, start, duration, sr=44100):\n",
        "  xstart = librosa.time_to_samples(start, sr=sr)\n",
        "  xduration = librosa.time_to_samples(start+duration, sr=sr)\n",
        "  audio_data = audio_data[:, xstart:xduration]\n",
        "  return audio_data\n",
        "\n",
        "def fade_audio(audio_data, fade_in=0.05, fade_out=0.05, sr=44100):\n",
        "  a_duration = librosa.get_duration(audio_data, sr=sr)\n",
        "  if fade_in > 0:\n",
        "    fade_in_to = librosa.time_to_samples(fade_in, sr=sr)\n",
        "    in_y = audio_data[:, 0:fade_in_to]\n",
        "    fade_ins = []\n",
        "    for channel in in_y:\n",
        "      fade = [ i/len(channel)*smp for i, smp in enumerate(channel) ]\n",
        "      fade_ins.append(fade)\n",
        "    fade_ins = np.array(fade_ins)\n",
        "    tail_start = fade_in_to+1\n",
        "    tail = audio_data[:, tail_start:]\n",
        "    audio_data = np.concatenate([fade_ins, tail], axis=1)\n",
        "  if fade_out > 0:\n",
        "    fade_out_start = librosa.time_to_samples(a_duration-fade_out, sr=sr)\n",
        "    out_y = audio_data[:, fade_out_start:]\n",
        "    fade_outs = []\n",
        "    for channel in out_y:\n",
        "      fade = [ smp-(i/len(channel)*smp) for i, smp in enumerate(channel) ]\n",
        "      fade_outs.append(fade)\n",
        "    fade_outs = np.array(fade_outs)\n",
        "    head_start = fade_out_start-1\n",
        "    head = audio_data[:, :head_start]\n",
        "    audio_data = np.concatenate([head, fade_outs], axis=1)\n",
        "  return audio_data\n",
        "\n",
        "def remove_silence(audio, window_size=0.2, threshold=0.1, save_as='', sr=44100):\n",
        "  if type(audio) != np.ndarray:\n",
        "    y, sr = librosa.load(audio, sr=None, mono=False)\n",
        "  else:\n",
        "    y = audio\n",
        "  audio_slices = slice_to_frames(y, window_size, sr=sr)\n",
        "  silence_removed_list = []\n",
        "  for audio_slice in audio_slices:\n",
        "    if max(audio_slice[0]) > threshold or max(audio_slice[1]) < -abs(threshold):\n",
        "      silence_removed_list.append(audio_slice)\n",
        "  silence_removed = np.concatenate(silence_removed_list, axis=1)\n",
        "  if save_as != '':\n",
        "    sf.write(save_as, silence_removed.T, sr)\n",
        "    return save_as\n",
        "  return silence_removed\n",
        "\n",
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n",
        "\n",
        "def get_audio_duration(file):\n",
        "  y, sr = librosa.load(voice_file, sr=None, mono=True)\n",
        "  return librosa.get_duration(y, sr=sr)\n",
        "\n",
        "def get_dir_size(dir_path='.'):\n",
        "  total_size = 0\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    for f in filenames:\n",
        "      fp = os.path.join(dirpath, f)\n",
        "      if not os.path.islink(fp):\n",
        "        total_size += os.path.getsize(fp)\n",
        "  return total_size\n",
        "\n",
        "def chop_to_sentences(text):\n",
        "  delimiter = '.'\n",
        "  temp = [e+delimiter for e in text.split(delimiter) if e]\n",
        "  sentences = []\n",
        "  for sentence in temp:\n",
        "    delimiter = '?'\n",
        "    if delimiter in sentence:\n",
        "      wtf = sentence.split(delimiter)\n",
        "      for f in wtf:\n",
        "        if f[-1] != '.' and f[-1] != '?' and f[-1] != '?':\n",
        "          f = f+'?'\n",
        "        if f != '':\n",
        "          sentences.append(f.strip())\n",
        "    elif sentence.strip() != '' and len(sentence.strip()) > 1:\n",
        "      sentences.append(sentence.strip())\n",
        "  return sentences\n",
        "\n",
        "# This will download all the models used by Tortoise from the HuggingFace hub.\n",
        "tts = TextToSpeech()\n",
        "\n",
        "output.clear()\n",
        "# !nvidia-smi\n",
        "op(c.ok, 'Setup finished.', time=True)"
      ],
      "metadata": {
        "id": "Zl44n6FXsbnY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fec2774b-7204-4b61-bc75-423c55fcd84d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2023-08-30 16:28:55 \u001b[92mSetup finished.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "46OP_UIHEs76"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import zipfile\n",
        "import soundfile as sf\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "folder_path = \"/content/faux_drive/fullset/\"\n",
        "zip_file = zipfile.ZipFile(\"/content/faux_drive/fullset/fimdom.zip\", 'w')\n",
        "for root, dirs, filez in os.walk(folder_path):\n",
        "    for file in tqdm(filez,desc=\"zipping files\"):\n",
        "        file_path = os.path.join(root, file)\n",
        "        extension = file_path.split('.')[-1]\n",
        "        files.download(file_path)\n",
        "        if extension in ('wav','mp3','flac'):\n",
        "\n",
        "          # Specify the paths for the input WAV file and output FLAC file\n",
        "          input_file = file_path\n",
        "          output_flac = file_path.replace('.'+extension,'.flac')\n",
        "          # Read the WAV file\n",
        "          data, samplerate = sf.read(input_file)\n",
        "\n",
        "          # Write the audio data to a FLAC file\n",
        "          sf.write(output_flac, data, samplerate, format='flac')\n",
        "          zip_file.write(output_flac, os.path.relpath(file_path, folder_path))\n",
        "          !rm -rf {file_path}\n",
        "        else:\n",
        "          zip_file.write(file_path, os.path.relpath(file_path, folder_path))\n",
        "          !rm -rf {file_path}\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "0UWYqXSbgROA",
        "outputId": "650333c3-baa1-4b53-84dc-931d6eaca204"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport zipfile\\nimport soundfile as sf\\nfrom tqdm import tqdm\\nfrom google.colab import files\\nfolder_path = \"/content/faux_drive/fullset/\"\\nzip_file = zipfile.ZipFile(\"/content/faux_drive/fullset/fimdom.zip\", \\'w\\')\\nfor root, dirs, filez in os.walk(folder_path):\\n    for file in tqdm(filez,desc=\"zipping files\"):\\n        file_path = os.path.join(root, file)\\n        extension = file_path.split(\\'.\\')[-1]\\n        files.download(file_path)\\n        if extension in (\\'wav\\',\\'mp3\\',\\'flac\\'):\\n\\n          # Specify the paths for the input WAV file and output FLAC file\\n          input_file = file_path\\n          output_flac = file_path.replace(\\'.\\'+extension,\\'.flac\\')\\n          # Read the WAV file\\n          data, samplerate = sf.read(input_file)\\n\\n          # Write the audio data to a FLAC file\\n          sf.write(output_flac, data, samplerate, format=\\'flac\\')\\n          zip_file.write(output_flac, os.path.relpath(file_path, folder_path))\\n          !rm -rf {file_path}\\n        else:\\n          zip_file.write(file_path, os.path.relpath(file_path, folder_path))\\n          !rm -rf {file_path}\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Audio tool installation\n",
        "#!pip install --upgrade youtube-dl\n",
        "!pip uninstall -y youtube_dl\n",
        "!pip install git+https://github.com/ytdl-org/youtube-dl.git@master#egg=youtube_dl\n",
        "\n",
        "!pip install sox\n",
        "!pip install pydub\n",
        "from pydub import AudioSegment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Go-6bUVpwzXf",
        "outputId": "a5041f76-dd4b-4a30-b46e-a41d5f28331c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: youtube-dl 2021.12.17\n",
            "Uninstalling youtube-dl-2021.12.17:\n",
            "  Successfully uninstalled youtube-dl-2021.12.17\n",
            "Collecting youtube_dl\n",
            "  Cloning https://github.com/ytdl-org/youtube-dl.git (to revision master) to /tmp/pip-install-3fvpgq29/youtube-dl_1217b5732bce45f0a1cdfe2b880941df\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/ytdl-org/youtube-dl.git /tmp/pip-install-3fvpgq29/youtube-dl_1217b5732bce45f0a1cdfe2b880941df\n",
            "  Resolved https://github.com/ytdl-org/youtube-dl.git to commit 86e3cf5e5849aefcc540c19bb5fa5ab7f470d1c1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: youtube_dl\n",
            "  Building wheel for youtube_dl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for youtube_dl: filename=youtube_dl-2021.12.17-py2.py3-none-any.whl size=1939858 sha256=8ba0dddc802e1473780d437d0fed0c7949f106d03438cc182d5c6156d8a6eb80\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zrfulz6e/wheels/b8/03/62/9c414b89a26da510b0a6d984b0ba74200d591e3d0abfa72aa8\n",
            "Successfully built youtube_dl\n",
            "Installing collected packages: youtube_dl\n",
            "Successfully installed youtube_dl-2021.12.17\n",
            "Requirement already satisfied: sox in /usr/local/lib/python3.10/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from sox) (1.23.5)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Download audio and process\n",
        "voices_settings = {\n",
        "    \"sarl\": [\n",
        "        {\n",
        "            'link': 'https://www.youtube.com/watch?v=wupToqz1e2g',\n",
        "            'start_sec': 0.21,\n",
        "            'end_sec': 9.29\n",
        "         },\n",
        "        {\n",
        "            'link':'https://www.youtube.com/watch?v=nGanLUnjoPI',\n",
        "            'start_sec': 60.56,\n",
        "            'end_sec': 75.56,\n",
        "        },\n",
        "         #       {\n",
        "        #    'link':'https://www.youtube.com/watch?v=UnURElCzGc0',\n",
        "        #    'start_sec': 3.372,\n",
        "        #    'end_sec': 17,\n",
        "        #},\n",
        "        #{\n",
        "        #    'link':'https://www.youtube.com/watch?v=UnURElCzGc0',\n",
        "        #    'start_sec': 3 * 60 + 26,\n",
        "        #    'end_sec': 3 * 60 + 42,\n",
        "        #},\n",
        "       #         {\n",
        "       #     'link':'https://www.loc.gov/item/cosmos000110/',\n",
        "       #     'start_sec': 0,\n",
        "      #     'end_sec': 20,\n",
        "      #  },\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ]\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "for voice, refs in voices_settings.items():\n",
        "  for r, ref in enumerate(refs):\n",
        "\n",
        "    #voice_path = '/content/tortoise-tts/tortoise/voices'\n",
        "    voices_path = os.path.join(drive_root,\"voices\")\n",
        "    voices_path = os.path.join(drive_root)\n",
        "    voice_path = os.path.join(voices_path,voice)\n",
        "    filename =  voice + '.mp4'\n",
        "    filepath = os.path.join(voice_path,filename)\n",
        "    chunkpath =  os.path.join(voice_path,str(r) + '.wav')\n",
        "    inputs_dir = os.path.join(drive_root,'voice_inputs')\n",
        "    input_name = ref[\"link\"].split(\"=\")[-1]\n",
        "    input_path = os.path.join(inputs_dir,input_name + '.wav')\n",
        "    if not os.path.isfile(input_path):\n",
        "      print(f'downloading {ref[\"link\"]} because {input_path} is not a file')\n",
        "      #command = f'mkdir {voices_path}; cd {voices_path} ; mkdir {voice} ; cd {voice_path};' + \\\n",
        "      #          f'youtube-dl -x --audio-format wav {ref[\"link\"]} --output \"{str(r)+\"_complete\"}.%(ext)s\"'\n",
        "\n",
        "      !mkdir {inputs_dir}\n",
        "\n",
        "      command = f\"cd {inputs_dir} && \" + \\\n",
        "                f'youtube-dl -x --audio-format wav {ref[\"link\"]} --output \"{input_name}.%(ext)s\"'\n",
        "\n",
        "      print('running command:')\n",
        "      print(command)\n",
        "      !{command}\n",
        "    else:\n",
        "      print(f'skipped downloading {ref[\"link\"]} because {input_path} exists')\n",
        "\n",
        "\n",
        "    !mkdir {os.path.dirname(chunkpath)}\n",
        "\n",
        "    #Trim\n",
        "    !rm -rf {chunkpath}\n",
        "    command = f\"sox {input_path} {chunkpath} trim {ref['start_sec']} {ref['end_sec'] - ref['start_sec']}\"\n",
        "    print('running command:')\n",
        "    print(command)\n",
        "    !{command}\n",
        "\n",
        "    #Normalize\n",
        "\n",
        "    audio = AudioSegment.from_file(chunkpath)\n",
        "    normalized_audio = audio.normalize()\n",
        "    compressed_audio = normalized_audio.compress_dynamic_range(threshold=-5,ratio=2,attack=5,release=50)\n",
        "    renormalized_audio = compressed_audio.normalize()\n",
        "    renormalized_audio.export(chunkpath, format=\"wav\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#!cd /content/faux_drive && youtube-dl --extract-audio --audio-format wav https://lotushelix.bandcamp.com/track/stranger-in-the-street --output \"stranger.wav\"\n",
        "#!cd /content/faux_drive && youtube-dl --extract-audio --audio-format wav https://lotushelix.bandcamp.com/track/live-life-in-love --output \"love.wav\"\n",
        "#!cd /content/faux_drive && youtube-dl --extract-audio --audio-format wav https://youtu.be/3u3JSEqNtlg --output \"technique.wav\"\n",
        "#!cd /content/faux_drive && youtube-dl --extract-audio --audio-format wav https://www.youtube.com/watch?v=wupToqz1e2g --output \"sagan.wav\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McYb8Om5xJF3",
        "outputId": "122d3d1a-c874-4140-df18-36bae641a2d1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "skipped downloading https://www.youtube.com/watch?v=wupToqz1e2g because /content/faux_drive/voice_inputs/wupToqz1e2g.wav exists\n",
            "mkdir: cannot create directory ‘/content/faux_drive/sarl’: File exists\n",
            "running command:\n",
            "sox /content/faux_drive/voice_inputs/wupToqz1e2g.wav /content/faux_drive/sarl/0.wav trim 0.21 9.079999999999998\n",
            "skipped downloading https://www.youtube.com/watch?v=nGanLUnjoPI because /content/faux_drive/voice_inputs/nGanLUnjoPI.wav exists\n",
            "mkdir: cannot create directory ‘/content/faux_drive/sarl’: File exists\n",
            "running command:\n",
            "sox /content/faux_drive/voice_inputs/nGanLUnjoPI.wav /content/faux_drive/sarl/1.wav trim 60.56 15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "import time\n",
        "from datetime import datetime\n",
        "#@title # Generate spoken word audio\n",
        "text = \"queen ay 1. queen ay 2. queen ay 3. queen ay 4. queen ay 5. queen ay 6. queen ay 7. queen ay 8. queen bee 1. queen bee 2. queen bee 3. queen bee 4. queen bee 5. queen bee 6. queen bee 7. queen bee 8. queen sea 1. queen sea 2. queen sea 3. queen sea 4. queen sea 5. queen sea 6. queen sea 7. queen sea 8. \" #@param {type:\"string\"}\n",
        "voice_audio = \"sarl\" #@param {type:\"string\"}\n",
        "combo_voice = False #@param {type:\"boolean\"}\n",
        "preset = \"high_quality\" #@param [\"standard\", \"fast\", \"ultra_fast\", \"high_quality\"]\n",
        "output_dir = \"fullset\" #@param {type:\"string\"}\n",
        "end_session_when_done = False #@param {type: \"boolean\"}\n",
        "save_sentences_as_they_render = False #@param {type: \"boolean\"}\n",
        "zip_sentences_and_download_all = True #@param {type: \"boolean\"}\n",
        "# @markdown `download_partial_zip_after_minutes <= 0` will disable this behavior\n",
        "download_partial_zip_after_minutes = 0 #@param {type:\"number\"}\n",
        "if download_partial_zip_after_minutes < 0:\n",
        "  download_partial_zip_after_minutes = 0\n",
        "\n",
        "save_txt = True\n",
        "timer_start = time.time()\n",
        "try:\n",
        "  uniq_id = gen_id()\n",
        "except:\n",
        "  raise Exception('Restart and run all')\n",
        "\n",
        "folder_path = \"/content/faux_drive/fullset/\"\n",
        "slice_length = 12 # seconds per slice\n",
        "use_slices = 5 # slices to use\n",
        "optimal_samples_duration = slice_length * use_slices # total duration\n",
        "sample_rate = 24000\n",
        "#process this many sentences in one go\n",
        "# @markdown try lowering `chunk_sentences` if you run out of VRAM. It worked with 8 with a high-RAM environment:\n",
        "chunk_sentences = 1 #@param {type:\"integer\", description:\"If you run out of (v)RAM try lowering this\"}\n",
        "dir_byte_limit = 48000000\n",
        "merge_sentences = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "start_time = datetime.now()\n",
        "if zip_sentences_and_download_all:\n",
        "  zip_name = uniq_id\n",
        "  zip_file = zipfile.ZipFile(f'{zip_name}.zip','w')\n",
        "\n",
        "\n",
        "if download_partial_zip_after_minutes:\n",
        "\n",
        "  partial_zip_num = 0\n",
        "  partial_zip_start_time = datetime.now()\n",
        "  partial_zip_name = f'{uniq_id}_{partial_zip_num}'\n",
        "  partial_zip_path = os.path.join(folder_path,\n",
        "                                partial_zip_name + '.zip')\n",
        "  partial_zip_file = zipfile.ZipFile(f'{partial_zip_path}','w',)\n",
        "  def close_zip_part():\n",
        "\n",
        "    global partial_zip_file, partial_zip_path\n",
        "    print(f\"closing {partial_zip_path}\")\n",
        "    # Finsh last one\n",
        "    partial_zip_file.close()\n",
        "    #print(f'sleeping for {10}s')\n",
        "    #time.sleep(10)\n",
        "    print(f\"trying to start download of {partial_zip_path}\")\n",
        "\n",
        "    files.download(partial_zip_path)\n",
        "    !wget -q http://www.yoursite.com/file.csv\n",
        "\n",
        "\n",
        "\n",
        "  def new_zip_part():\n",
        "    global partial_zip_num\n",
        "    global partial_zip_start_time, partial_zip_name\n",
        "    global partial_zip_path, partial_zip_file\n",
        "      # INIT partial_zip\n",
        "    close_zip_part()\n",
        "    #start next one\n",
        "    partial_zip_num += 1\n",
        "    partial_zip_start_time = datetime.now()\n",
        "    partial_zip_name = f'{uniq_id}_{partial_zip_num}'\n",
        "    partial_zip_path = os.path.join(folder_path,\n",
        "                                    partial_zip_name + '.zip')\n",
        "    partial_zip_file = zipfile.ZipFile(f'{partial_zip_path}','w',)\n",
        "    print('created {partial_zip_path}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "op(c.title, 'Run ID:', uniq_id, time=True)\n",
        "print()\n",
        "\n",
        "voice_corpus = voice_audio\n",
        "prompts = chop_to_sentences(text)\n",
        "\n",
        "if chunk_sentences > 1:\n",
        "  prompts = [''.join(prompts[i:i+chunk_sentences]) for i in range(0, len(prompts), chunk_sentences)]\n",
        "\n",
        "clean_dirs([dir_tmp_corpus, dir_tmp_slices, dir_tmp_clips, dir_tmp_processed])\n",
        "\n",
        "if os.path.isfile(drive_root+voice_corpus):\n",
        "  clean_dirs([dir_tmp_corpus])\n",
        "  shutil.copy(drive_root+voice_corpus, dir_tmp_corpus)\n",
        "  voice_dirs = [dir_tmp_corpus]\n",
        "else:\n",
        "  if voice_corpus == 'voice_list':\n",
        "    voice_dirs = [drive_root+x for x in voice_list]\n",
        "  elif ',' in voice_corpus:\n",
        "    voice_dirs = [drive_root+fix_path(x.strip()) for x in voice_corpus.split(',')]\n",
        "  elif ';' in voice_corpus:\n",
        "    voice_dirs = [drive_root+fix_path(x.strip()) for x in voice_corpus.split(';')]\n",
        "  else:\n",
        "    voice_dirs = [drive_root+fix_path(voice_corpus)]\n",
        "\n",
        "# Output\n",
        "if output_dir == '':\n",
        "  if mount_drive == True:\n",
        "    dir_out = dir_tmp\n",
        "  else:\n",
        "    dir_out = drive_root\n",
        "else:\n",
        "  if not os.path.isdir(drive_root+output_dir):\n",
        "    os.mkdir(drive_root+output_dir)\n",
        "  dir_out = drive_root+fix_path(output_dir)\n",
        "\n",
        "total = len(voice_dirs * len(prompts))\n",
        "use_voices = []\n",
        "\n",
        "txt_file = dir_out+uniq_id+'.txt'\n",
        "if save_txt: append_txt(txt_file, timestamp(human_readable=True)+' '+uniq_id+'\\n\\n'+text+'\\n\\n'+'combo_voice: '+str(combo_voice)+'\\n'+'preset: '+preset+'\\n'+'dir_out: '+dir_out+'\\n\\n')\n",
        "\n",
        "for i, voice_dir in enumerate(voice_dirs, 1):\n",
        "  if voice_dir == dir_tmp_corpus:\n",
        "    voice_name = basename(voice_corpus)\n",
        "  else:\n",
        "    voice_name = path_leaf(voice_dir)\n",
        "\n",
        "  use_voices.append(voice_name)\n",
        "  new_voice_dir = '/content/tortoise-tts/tortoise/voices/'+voice_name+'/'\n",
        "  if not os.path.isdir(new_voice_dir):\n",
        "    os.mkdir(new_voice_dir)\n",
        "  else:\n",
        "    clean_dirs([new_voice_dir])\n",
        "  voice_files = list_audio(voice_dir)\n",
        "\n",
        "  random.shuffle(voice_files)\n",
        "\n",
        "  if save_txt: append_txt(txt_file, voice_name+'\\n'+'In: '+voice_dir)\n",
        "\n",
        "  if len(voice_files) == 0:\n",
        "    print()\n",
        "    op(c.fail, 'Skipping '+voice_name+' - Reason: WAV files not found in dir:', voice_dir.replace(drive_root, ''), time=True)\n",
        "    if save_txt: append_txt(txt_file, 'Out: - (no wav found, SKIP)\\n')\n",
        "  else:\n",
        "    op(c.okb, 'Processing voice files...', time=True)\n",
        "    bytes_collected = 0\n",
        "    for voice_file in voice_files:\n",
        "      voice_file = remove_silence(voice_file, window_size=2, threshold=0.1, save_as=dir_tmp_processed+path_leaf(voice_file))\n",
        "      file_duration = get_audio_duration(voice_file)\n",
        "      slice_file = dir_tmp_slices+path_leaf(voice_file)\n",
        "\n",
        "      if file_duration > slice_length:\n",
        "        !sox {sox_q} \"{voice_file}\" -r 22050 {slice_file} trim 0 {slice_length} : newfile : restart\n",
        "      else:\n",
        "        !sox {sox_q} \"{voice_file}\" -r 22050 {slice_file}\n",
        "\n",
        "      clips = list_audio(dir_tmp_slices)\n",
        "\n",
        "      short_clips = []\n",
        "      long_clips = []\n",
        "      for clip in clips:\n",
        "        clip_duration = get_audio_duration(clip)\n",
        "        if clip_duration >= slice_length:\n",
        "          long_clips.append(clip)\n",
        "        else:\n",
        "          short_clips.append(clip)\n",
        "        if (len(long_clips)*slice_length >= optimal_samples_duration):\n",
        "          break\n",
        "\n",
        "      if len(long_clips) >= use_slices:\n",
        "        selected_clips = random.sample(long_clips, use_slices)\n",
        "      else:\n",
        "        selected_clips = clips\n",
        "\n",
        "      if save_txt: append_txt(txt_file, 'Selected clips:')\n",
        "      for clip in selected_clips:\n",
        "        if save_txt: append_txt(txt_file, path_leaf(clip)+'\\n')\n",
        "        shutil.copy(clip, new_voice_dir)\n",
        "\n",
        "      file_size = os.path.getsize(voice_file)\n",
        "      bytes_collected += file_size\n",
        "      if bytes_collected > dir_byte_limit:\n",
        "        break\n",
        "\n",
        "    merge_list = []\n",
        "    for ii, text in enumerate(prompts, 1):\n",
        "\n",
        "      ndx_info = str(i*ii)+'/'+str(total)+' '\n",
        "\n",
        "      voice_samples = None\n",
        "      conditioning_latents = None\n",
        "      gen = None\n",
        "\n",
        "      print()\n",
        "      op(c.title, ndx_info+'Processing', voice_name, time=True)\n",
        "\n",
        "      if combo_voice == False:\n",
        "        op(c.title, ndx_info+'Synthesizing', text+'...', time=True)\n",
        "\n",
        "        file_out = dir_out+uniq_id+'__'+voice_name+'_'+str(ii).zfill(3)+'_'+slug(text[:60])+'.wav'\n",
        "        if save_txt: append_txt(txt_file, 'Out: '+file_out+'\\n')\n",
        "        voice_samples, conditioning_latents = load_voice(voice_name)\n",
        "        gen = tts.tts_with_preset(text, voice_samples=voice_samples, conditioning_latents=conditioning_latents, preset=preset)\n",
        "        torchaudio.save(file_out, gen.squeeze(0).cpu(), sample_rate)\n",
        "        if os.path.isfile(file_out):\n",
        "          op(c.ok, 'Saved', file_out.replace(drive_root, ''), time=True)\n",
        "          merge_list.append(file_out)\n",
        "          if save_sentences_as_they_render:\n",
        "            files.download(file_out)\n",
        "          if zip_sentences_and_download_all:\n",
        "            print(f'adding {file_out} to {zip_name}.zip')\n",
        "            #zip_file.write(file_out,\n",
        "            #  os.path.relpath(partial_zip_path, folder_path))\n",
        "            zip_file.write(file_out)\n",
        "          if bool(download_partial_zip_after_minutes):\n",
        "            print(f'adding {file_out} to {partial_zip_file}.zip')\n",
        "            partial_zip_file.write(file_out,\n",
        "              os.path.relpath(partial_zip_path, folder_path)) #HERE\n",
        "            elapsed = datetime.now() -partial_zip_start_time\n",
        "            minutes = elapsed.total_seconds() / 60\n",
        "            if ii == (len(prompts) - 1):\n",
        "              close_zip_part()\n",
        "            elif minutes > download_partial_zip_after_minutes:\n",
        "              new_zip_part()\n",
        "\n",
        "        else:\n",
        "          op(c.fail, 'Error saving', file_out.replace(drive_root, ''), time=True)\n",
        "\n",
        "        del voice_samples\n",
        "        del conditioning_latents\n",
        "        del gen\n",
        "\n",
        "      torch.cuda.empty_cache()\n",
        "      import gc\n",
        "      gc.collect()\n",
        "\n",
        "    if merge_sentences == True:\n",
        "      sox_input_list = ' '.join(merge_list)\n",
        "      sox_merge_out = dir_out+uniq_id+'__'+voice_name+'_FULL.wav'\n",
        "      !sox {sox_q} {sox_input_list} {sox_merge_out}\n",
        "\n",
        "if combo_voice == True:\n",
        "   for text in prompts:\n",
        "     print()\n",
        "     op(c.title, 'Synthesizing', text[:40]+'...', time=True)\n",
        "     file_out = dir_out+uniq_id+'__'+voice_name+'_'+slug(text[:60])+'.wav'\n",
        "     if save_txt == True:\n",
        "       append_txt(txt_file, 'Out: '+file_out+'\\n')\n",
        "     voice_samples, conditioning_latents = load_voices(use_voices)\n",
        "     gen = tts.tts_with_preset(text, voice_samples=voice_samples, conditioning_latents=conditioning_latents, preset=preset)\n",
        "     torchaudio.save(file_out, gen.squeeze(0).cpu(), sample_rate)\n",
        "     if save_sentences_as_they_render:\n",
        "      files.download(file_out)\n",
        "\n",
        "     # IPython.display.Audio(file_out)\n",
        "\n",
        "     del voice_samples\n",
        "     del conditioning_latents\n",
        "     del gen\n",
        "     del tts\n",
        "     torch.cuda.empty_cache()\n",
        "     import gc\n",
        "     gc.collect()\n",
        "\n",
        "\n",
        "timer_end = time.time()\n",
        "\n",
        "print()\n",
        "\n",
        "if save_txt: append_txt(txt_file, str(timedelta(seconds=timer_end-timer_start)) )\n",
        "if save_txt: append_txt(txt_file, 'Finished at '+timestamp(human_readable=True))\n",
        "if zip_sentences_and_download_all:\n",
        "  zip_file.write(txt_file)\n",
        "files.download(f'{zip_name}.zip')\n",
        "\n",
        "op(c.okb, 'Elapsed', timedelta(seconds=timer_end-timer_start), time=True)\n",
        "op(c.ok, 'FIN.')\n",
        "\n",
        "if end_session_when_done is True: end_session()"
      ],
      "metadata": {
        "id": "DjMTvst0z2ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a8721f0-66ad-4ba8-c5ef-39512f77f55c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2023-08-30 22:06:45 \u001b[96mRun ID:\u001b[0m moflom\n",
            "\n",
            "\u001b[90m2023-08-30 22:06:45 \u001b[94mProcessing voice files...\u001b[0m\n",
            "\n",
            "\u001b[90m2023-08-30 22:06:46 \u001b[96m1/24 Processing\u001b[0m sarl\n",
            "\u001b[90m2023-08-30 22:06:46 \u001b[96m1/24 Synthesizing\u001b[0m queen ay 1....\n",
            "Generating autoregressive samples..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [02:23<00:00,  8.95s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing best candidates using CLVP\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:13<00:00,  1.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transforming autoregressive outputs into audio..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [00:21<00:00, 18.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2023-08-30 22:09:50 \u001b[92mSaved\u001b[0m fullset/moflom__sarl_001_queen_ay_1..wav\n",
            "adding /content/faux_drive/fullset/moflom__sarl_001_queen_ay_1..wav to moflom.zip\n",
            "\n",
            "\u001b[90m2023-08-30 22:09:51 \u001b[96m2/24 Processing\u001b[0m sarl\n",
            "\u001b[90m2023-08-30 22:09:51 \u001b[96m2/24 Synthesizing\u001b[0m queen ay 2....\n",
            "Generating autoregressive samples..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [02:14<00:00,  8.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing best candidates using CLVP\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:13<00:00,  1.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transforming autoregressive outputs into audio..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [00:22<00:00, 18.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2023-08-30 22:12:47 \u001b[92mSaved\u001b[0m fullset/moflom__sarl_002_queen_ay_2..wav\n",
            "adding /content/faux_drive/fullset/moflom__sarl_002_queen_ay_2..wav to moflom.zip\n",
            "\n",
            "\u001b[90m2023-08-30 22:12:47 \u001b[96m3/24 Processing\u001b[0m sarl\n",
            "\u001b[90m2023-08-30 22:12:47 \u001b[96m3/24 Synthesizing\u001b[0m queen ay 3....\n",
            "Generating autoregressive samples..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [02:19<00:00,  8.75s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing best candidates using CLVP\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:13<00:00,  1.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transforming autoregressive outputs into audio..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [00:22<00:00, 18.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2023-08-30 22:15:49 \u001b[92mSaved\u001b[0m fullset/moflom__sarl_003_queen_ay_3..wav\n",
            "adding /content/faux_drive/fullset/moflom__sarl_003_queen_ay_3..wav to moflom.zip\n",
            "\n",
            "\u001b[90m2023-08-30 22:15:49 \u001b[96m4/24 Processing\u001b[0m sarl\n",
            "\u001b[90m2023-08-30 22:15:49 \u001b[96m4/24 Synthesizing\u001b[0m queen ay 4....\n",
            "Generating autoregressive samples..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [02:05<00:00,  7.86s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing best candidates using CLVP\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:13<00:00,  1.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transforming autoregressive outputs into audio..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [00:22<00:00, 18.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2023-08-30 22:18:37 \u001b[92mSaved\u001b[0m fullset/moflom__sarl_004_queen_ay_4..wav\n",
            "adding /content/faux_drive/fullset/moflom__sarl_004_queen_ay_4..wav to moflom.zip\n",
            "\n",
            "\u001b[90m2023-08-30 22:18:37 \u001b[96m5/24 Processing\u001b[0m sarl\n",
            "\u001b[90m2023-08-30 22:18:37 \u001b[96m5/24 Synthesizing\u001b[0m queen ay 5....\n",
            "Generating autoregressive samples..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [01:47<00:00,  6.74s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing best candidates using CLVP\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:13<00:00,  1.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transforming autoregressive outputs into audio..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [00:25<00:00, 15.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2023-08-30 22:21:10 \u001b[92mSaved\u001b[0m fullset/moflom__sarl_005_queen_ay_5..wav\n",
            "adding /content/faux_drive/fullset/moflom__sarl_005_queen_ay_5..wav to moflom.zip\n",
            "\n",
            "\u001b[90m2023-08-30 22:21:11 \u001b[96m6/24 Processing\u001b[0m sarl\n",
            "\u001b[90m2023-08-30 22:21:11 \u001b[96m6/24 Synthesizing\u001b[0m queen ay 6....\n",
            "Generating autoregressive samples..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [02:42<00:00, 10.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing best candidates using CLVP\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:13<00:00,  1.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transforming autoregressive outputs into audio..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [00:25<00:00, 15.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2023-08-30 22:24:38 \u001b[92mSaved\u001b[0m fullset/moflom__sarl_006_queen_ay_6..wav\n",
            "adding /content/faux_drive/fullset/moflom__sarl_006_queen_ay_6..wav to moflom.zip\n",
            "\n",
            "\u001b[90m2023-08-30 22:24:38 \u001b[96m7/24 Processing\u001b[0m sarl\n",
            "\u001b[90m2023-08-30 22:24:38 \u001b[96m7/24 Synthesizing\u001b[0m queen ay 7....\n",
            "Generating autoregressive samples..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [02:24<00:00,  9.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing best candidates using CLVP\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:13<00:00,  1.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transforming autoregressive outputs into audio..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [00:21<00:00, 18.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2023-08-30 22:27:44 \u001b[92mSaved\u001b[0m fullset/moflom__sarl_007_queen_ay_7..wav\n",
            "adding /content/faux_drive/fullset/moflom__sarl_007_queen_ay_7..wav to moflom.zip\n",
            "\n",
            "\u001b[90m2023-08-30 22:27:44 \u001b[96m8/24 Processing\u001b[0m sarl\n",
            "\u001b[90m2023-08-30 22:27:44 \u001b[96m8/24 Synthesizing\u001b[0m queen ay 8....\n",
            "Generating autoregressive samples..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [02:18<00:00,  8.68s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing best candidates using CLVP\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:13<00:00,  1.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transforming autoregressive outputs into audio..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▎      | 130/400 [00:07<00:14, 18.14it/s]"
          ]
        }
      ]
    }
  ]
}